{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NormalLR:\n",
    "    def __init__(self, τ=0):\n",
    "        self.τ = τ\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.weights = np.linalg.inv(X.T.dot(X) + self.τ * np.eye(X.shape[1])).dot(X.T).dot(y[:,np.newaxis])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X.dot(self.weights).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GradientLR(NormalLR):\n",
    "    def __init__(self, alpha=0.1, τ=0):\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"alpha should be positive\")\n",
    "        self.α = alpha\n",
    "        self.τ = τ\n",
    "        self.threshold = alpha / 100\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        l = len(y)\n",
    "        w = np.random.rand(X.shape[1], 1) / l - 1 / (2 * l)\n",
    "        \n",
    "        it = 5\n",
    "        \n",
    "        while True:\n",
    "            w_prev = w.copy()\n",
    "            w = w - self.α * (np.sum((X.dot(w) - y[:, np.newaxis]) * X, axis=0)[:, np.newaxis] / l\n",
    "                              + self.τ * np.linalg.norm(w))\n",
    "            if np.abs(w - w_prev).sum() < self.threshold:\n",
    "                break\n",
    "                \n",
    "        self.weights = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.square(y_true - y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(size, weights):\n",
    "    X = np.ones((size, 2))\n",
    "    X[:, 1] = np.random.gamma(4., 2., size)\n",
    "    y = X.dot(np.asarray(weights))\n",
    "    y += np.random.normal(0, 1, size)\n",
    "    return X[:, 1:], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121.97976119075041, 121.98018805693238]\n",
      "[123.25128491762437, 123.25178165550771]\n",
      "[114.58511495033076, 114.58554456699545]\n",
      "[112.11069149257645, 112.11169218375906]\n",
      "[115.3386654028703, 115.33952189277605]\n",
      "[114.4274312334631, 114.42844394290509]\n"
     ]
    }
   ],
   "source": [
    "for size in [64, 128, 256, 512, 1024, 2048]:\n",
    "    X, y_true = sample(size, weights=[24., 42.])\n",
    "    X = X / (X.max(axis=0) - X.min(axis=0))\n",
    "    err = []\n",
    "    for model in [NormalLR, GradientLR]:\n",
    "        lr = model()\n",
    "        lr.fit(X, y_true)\n",
    "        y_pred = lr.predict(X)\n",
    "        err.append(mse(y_true, y_pred))\n",
    "        \n",
    "    print(err)\n",
    "\n",
    "# plt.scatter(X, y_true)\n",
    "# plt.plot(X, lr.predict(X), color='r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('boston.csv', delimiter=',')\n",
    "\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "# X = (X - X.mean(axis=0)) / X.std(axis=0) # scaling\n",
    "# X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X = X / (X.max(axis=0) - X.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: NormalLR, τ: 0, error: 36115317.53130742\n",
      "[-10577.25840952   4559.14621681   -622.27368153   2486.45168579\n",
      "    -84.28814287  31255.65021846  -1130.28442777  -9269.33644611\n",
      "   2471.28712702  -4280.38362407  -4741.83708227   5639.65882566\n",
      " -13333.02671363]\n",
      "\n",
      "model: NormalLR, τ: 0.01, error: 36116471.7818533\n",
      "[-10519.87710018   4555.66426936   -631.52355712   2490.14797943\n",
      "    -65.51127196  31219.00963177  -1123.25827563  -9236.75873745\n",
      "   2454.18564353  -4269.44953267  -4736.50452986   5640.32195437\n",
      " -13345.27667281]\n",
      "\n",
      "model: NormalLR, τ: 0.1, error: 36134383.55763875\n",
      "[-10033.02117813   4526.42634973   -712.54713296   2522.23744682\n",
      "     97.22712387  30897.55081813  -1062.89256236  -8953.48850646\n",
      "   2307.19879543  -4175.0356719   -4688.99248516   5646.83336633\n",
      " -13446.07701226]\n",
      "\n",
      "model: NormalLR, τ: 0.5, error: 36328836.02138009\n",
      "[ -8365.41124526   4432.24622756  -1029.66599605   2643.70436852\n",
      "    706.09506605  29622.43436255   -845.33169358  -7872.98843236\n",
      "   1773.32198811  -3826.41905412  -4486.8074623    5684.40598993\n",
      " -13731.71917105]\n",
      "\n",
      "model: NormalLR, τ: 1, error: 36709007.74784076\n",
      "[ -6996.58562602   4367.15295946  -1347.25978731   2760.62308066\n",
      "   1274.62511538  28293.3042141    -653.73894679  -6815.30869606\n",
      "   1287.50792584  -3504.49834467  -4250.06414859   5741.63877129\n",
      " -13846.42586221]\n",
      "\n",
      "model: NormalLR, τ: 5, error: 40311245.431981415\n",
      "[ -3492.79809274   4345.80610145  -2470.89887012   3141.9252519\n",
      "   2939.11521857  22148.09498907   -158.07541092  -2715.37035401\n",
      "   -379.17455743  -2469.7451078   -2710.81042278   6132.48487893\n",
      " -12382.78493223]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [NormalLR]:\n",
    "    for τ in [0, 0.01, 0.1, 0.5, 1, 5]:\n",
    "        lr = model(τ=τ)\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        print(\"model: {m}, τ: {t}, error: {e}\".format(m=model.__name__, t=τ, e=mse(y_test, y_pred)))\n",
    "        print(lr.weights.T[0])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: NormalLR, τ: 5, error: 36115181.32439986\n",
      "[-10576.08185308   4559.07834107   -622.26945853   2486.47885806\n",
      "    -84.20614854  31255.54505389  -1130.22319253  -9269.13526355\n",
      "   2471.06930807  -4280.30025671  -4741.83161158   5639.64233762\n",
      " -13333.28491732]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = GradientLR()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"model: {m}, τ: {t}, error: {e}\".format(m=model.__name__, t=τ, e=mse(y_test, y_pred)))\n",
    "print(lr.weights.T[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
