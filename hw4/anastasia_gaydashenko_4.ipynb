{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_train_split(X, y):\n",
    "    train = np.array([], dtype=np.int64)\n",
    "    test = np.array([], dtype=np.int64)\n",
    "    for cl in np.unique(y):\n",
    "        class_indeces = np.where(y == cl)[0]\n",
    "        train = np.append(train, class_indeces[:int(0.8*class_indeces.shape[0])])\n",
    "        test = np.append(test, class_indeces[int(0.8*class_indeces.shape[0]):])\n",
    "        \n",
    "    return X[train], y[train], X[test], y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words(X):\n",
    "    punctuation = string.punctuation+'…'+'“'+'–'+'‘'+'£'+'»'\n",
    "    X = np.core.chararray.lower(X)\n",
    "    X = np.core.chararray.translate(X, str.maketrans(punctuation, ' '*len(punctuation))) # remove punctuation\n",
    "    X = np.core.chararray.translate(X, str.maketrans(string.digits, ' '*len(string.digits))) # remove digits\n",
    "    return np.core.chararray.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(X):\n",
    "    dictionary = {}\n",
    "    \n",
    "    pure_words = get_words(X)\n",
    "    tmp = np.unique(np.array([word for message in pure_words for word in message]))\n",
    "    \n",
    "    for i, word in enumerate(tmp):\n",
    "        dictionary[word] = i\n",
    "        \n",
    "    X_hashed = np.array([[dictionary[word] for word in message] for message in pure_words])\n",
    "    \n",
    "    vectorization = np.zeros((len(X), len(dictionary)), dtype=np.int64)\n",
    "    for i, message in enumerate(X_hashed):\n",
    "        for word in message:\n",
    "            vectorization[i, word] = vectorization[i, word] + 1\n",
    "            \n",
    "    return vectorization, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, X = np.core.chararray.decode(np.loadtxt(\n",
    "        codecs.open('spam', encoding='latin1'), dtype=np.bytes_, delimiter='\\t', unpack=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = test_train_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        self.classes_prior_prob = np.array([], dtype=np.float64)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.classes = np.unique(y)\n",
    "        \n",
    "        vectorization, self.dictionary = vectorize(X)\n",
    "        self.dict_size = vectorization.shape[1]\n",
    "        self.classes_words_count = np.zeros(len(self.classes), dtype=np.float64)\n",
    "        self.words_cond_prob = np.zeros((len(self.classes), self.dict_size), dtype=np.float64)\n",
    "        \n",
    "        for i, cl in enumerate(self.classes):\n",
    "            indeces = y == cl\n",
    "            self.classes_prior_prob = np.append(self.classes_prior_prob, np.sum(indeces)/len(y))\n",
    "            self.classes_words_count[i] = np.sum(vectorization[indeces])\n",
    "            \n",
    "            for j in range(self.dict_size):\n",
    "                self.words_cond_prob[i,j] = np.sum(vectorization[indeces,j])\n",
    "            \n",
    "        \n",
    "        self.words_cond_prob = np.concatenate((self.words_cond_prob, np.array([[0,0]]).T), axis=1)\n",
    "        self.words_cond_prob = self.words_cond_prob + self.alpha\n",
    "        for i, _ in enumerate(self.classes):\n",
    "            self.words_cond_prob[i] = self.words_cond_prob[i] / (self.classes_words_count[i] + self.alpha*self.dict_size)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for message in get_words(X):\n",
    "            ind = np.array([self.dictionary[word] if word in self.dictionary else self.dict_size for word in message])\n",
    "            if len(ind) == 0:\n",
    "                result.append(self.classes[np.argmax(np.log(self.classes_prior_prob))])\n",
    "            else:\n",
    "                result.append(self.classes[np.argmax(np.log(self.classes_prior_prob) \n",
    "                                                 + np.sum(np.log(self.words_cond_prob[:,ind]), axis=1))])\n",
    "        return result\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return np.sum(self.predict(X) == y)/len(y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97670250896057342"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99147599820547327"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
